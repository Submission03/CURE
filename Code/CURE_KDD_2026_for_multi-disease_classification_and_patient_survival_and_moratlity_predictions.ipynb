{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "sns.set_style('whitegrid')\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense , Flatten , Conv2D , MaxPooling2D , Dropout , Activation , BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam , Adamax\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "#Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, ReLU, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import KLDivergence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications import DenseNet121, ResNet50V2\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, ReLU, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import KLDivergence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications import DenseNet169, MobileNetV2, ResNet50, EfficientNetB0\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "import copy\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.constraints import MinMaxNorm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.initializers import HeNormal, RandomNormal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install lifelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from lifelines.utils import concordance_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modality 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_h = np.load('ham10000/x_train.npy')\n",
    "y_train_h = np.load('ham10000/y_train.npy')\n",
    "X_test_h = np.load('ham10000/x_test.npy')\n",
    "y_test_h = np.load('ham10000/y_test.npy')\n",
    "\n",
    "X_val_h = np.load('ham10000/x_val.npy')\n",
    "y_val_h = np.load('ham10000/y_val.npy')\n",
    "\n",
    "\n",
    "X_train_h.shape, y_train_h.shape, X_test_h.shape, y_test_h.shape, X_val_h.shape, y_val_h.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "random_indices = np.random.choice(1001, 810, replace=False)\n",
    "\n",
    "X_test_h1 = X_test_h[random_indices]\n",
    "y_test_h1 = y_test_h[random_indices]\n",
    "\n",
    "X_test_h1.shape, y_test_h1.shape, X_test_h.shape, y_test_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "random_indices = np.random.choice(1002, 648, replace=False)\n",
    "\n",
    "X_val_h1 = X_val_h[random_indices]\n",
    "y_val_h1 = y_val_h[random_indices]\n",
    "\n",
    "X_test_h1.shape, y_test_h1.shape, X_test_h.shape, y_test_h.shape, X_val_h1.shape, y_val_h1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modality 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_s = np.load('SIPAKMED/features.npy')\n",
    "y_train_s = np.load('SIPAKMED/labels.npy')\n",
    "\n",
    "X_train_s.shape, y_train_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_train_s, y_train_s, test_size=0.2, random_state=42)\n",
    "X_train_s, X_val_s, y_train_s, y_val_s = train_test_split(X_train_s, y_train_s, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_s.shape,X_test_s.shape, y_train_s.shape,y_test_s.shape, y_val_s.shape,y_val_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    \"\"\"\n",
    "    Rotate the image by the specified angle.\n",
    "    \"\"\"\n",
    "    center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return rotated_image\n",
    "\n",
    "def translate_image(image, tx, ty):\n",
    "    \"\"\"\n",
    "    Translate the image by the specified translation parameters.\n",
    "    \"\"\"\n",
    "    translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "    translated_image = cv2.warpAffine(image, translation_matrix, image.shape[1::-1])\n",
    "    return translated_image\n",
    "\n",
    "def apply_gaussian_blur(image, kernel_size=3):\n",
    "    \"\"\"\n",
    "    Apply Gaussian Blur to the image to reduce noise and improve generalization.\n",
    "    \"\"\"\n",
    "    blurred_image = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "    return blurred_image\n",
    "\n",
    "# Augmentation parameters\n",
    "rotation_angles = [20]\n",
    "translations = [(5, 5)]\n",
    "kernel_sizes = [3]  # Gaussian Blur kernel sizes\n",
    "\n",
    "augmented_X_train = []\n",
    "augmented_y_train = []\n",
    "\n",
    "for image, label in zip(X_train_s, y_train_s):\n",
    "    # Augment with rotations\n",
    "    for angle in rotation_angles:\n",
    "        rotated_image = rotate_image(image, angle)\n",
    "        augmented_X_train.append(rotated_image)\n",
    "        augmented_y_train.append(label)\n",
    "\n",
    "    # Augment with translations\n",
    "    for tx, ty in translations:\n",
    "        translated_image = translate_image(image, tx, ty)\n",
    "        augmented_X_train.append(translated_image)\n",
    "        augmented_y_train.append(label)\n",
    "\n",
    "    # Augment with Gaussian Blur\n",
    "    for kernel_size in kernel_sizes:\n",
    "        blurred_image = apply_gaussian_blur(image, kernel_size)\n",
    "        augmented_X_train.append(blurred_image)\n",
    "        augmented_y_train.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "augmented_X_train = np.array(augmented_X_train)\n",
    "augmented_y_train = np.array(augmented_y_train)\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle_indices = np.random.permutation(len(augmented_X_train))\n",
    "augmented_X_train = augmented_X_train[shuffle_indices]\n",
    "augmented_y_train = augmented_y_train[shuffle_indices]\n",
    "augmented_X_train.shape, augmented_y_train.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "random_indices = np.random.choice(7773, 5421, replace=False)\n",
    "\n",
    "augmented_X_train = augmented_X_train[random_indices]\n",
    "augmented_y_train = augmented_y_train[random_indices]\n",
    "\n",
    "augmented_X_train.shape, augmented_y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_s = np.concatenate((X_train_s, augmented_X_train), axis=0)\n",
    "y_train_s = np.concatenate((y_train_s, augmented_y_train), axis=0)\n",
    "X_train_s.shape, y_train_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#del augmented_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Normalize from [0, 255] to [0, 1]\n",
    "X_train_s = X_train_s.astype(np.float32) / 255.0\n",
    "X_test_s = X_test_s.astype(np.float32) / 255.0\n",
    "X_val_s = X_val_s.astype(np.float32) / 255.0\n",
    "\n",
    "X_train_s.shape, X_test_s.shape, X_val_s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modality 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_multi = np.load('X_train_img_BRCA_updated.npy')\n",
    "X_val_multi = np.load('X_val_img_BRCA_updated.npy')\n",
    "X_test_multi = np.load('X_test_img_BRCA_updated.npy')\n",
    "\n",
    "y_train_multi = np.load('y_train_tab_BRCA_updated.npy')\n",
    "y_val_multi = np.load('y_val_tab_BRCA_updated.npy')\n",
    "y_test_multi = np.load('y_test_tab_BRCA_updated.npy')\n",
    "\n",
    "X_train_multi.shape, X_val_multi.shape, X_test_multi.shape, y_train_multi.shape, y_val_multi.shape, y_test_multi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modality 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_m1 = np.load('X_train_MORT_MIMIC3_updated.npy')\n",
    "y_train_m1 = np.load('y_train_MORT_MIMIC3_updated.npy')\n",
    "X_test_m1 = np.load('X_test_MORT_MIMIC3_updated.npy')\n",
    "y_test_m1 = np.load('y_test_MORT_MIMIC3_updated.npy')\n",
    "\n",
    "X_val_m1 = np.load('X_val_MORT_MIMIC3_updated.npy')\n",
    "y_val_m1 = np.load('y_val_MORT_MIMIC3_updated.npy')\n",
    "\n",
    "X_train_m1.shape, y_train_m1.shape, X_test_m1.shape, y_test_m1.shape, X_val_m1.shape, y_val_m1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## HySAM\n",
    "\n",
    "\n",
    "\n",
    "class GlobalMinPooling2D(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GlobalMinPooling2D, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.reduce_min(inputs, axis=[1, 2])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(GlobalMinPooling2D, self).get_config()\n",
    "        return config\n",
    "\n",
    "class MACFusion(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation='sigmoid', fractal_dim=1.8, learnable_curvature=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.fractal_dim = fractal_dim\n",
    "        self.learnable_curvature = learnable_curvature\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[0][-1]\n",
    "        self.feature_dim = feature_dim\n",
    "\n",
    "        self.global_avg_pooling = layers.GlobalAveragePooling2D()\n",
    "        self.global_max_pooling = layers.GlobalMaxPooling2D()\n",
    "        self.global_min_pooling = GlobalMinPooling2D()\n",
    "\n",
    "        self.global_attention = layers.Dense(units=self.units, activation=self.activation)\n",
    "        self.global_scale1 = self.add_weight(shape=(1, 1, 1, 1), initializer=tf.keras.initializers.HeNormal(), trainable=True, name='global_scale1')\n",
    "        self.global_scale2 = self.add_weight(shape=(1, 1, 1, 1), initializer=tf.keras.initializers.HeNormal(), trainable=True, name='global_scale2')\n",
    "        \n",
    "        # Quantum Components\n",
    "        self.psi_real = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                        initializer='glorot_uniform', name='psi_real')\n",
    "        self.psi_imag = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                        initializer='glorot_uniform', name='psi_imag')\n",
    "        self.S = self.add_weight(shape=(self.units,),\n",
    "                                 initializer=tf.keras.initializers.Constant(self.fractal_dim),\n",
    "                                 constraint=MinMaxNorm(1.0, 2.0),\n",
    "                                 name='fractal_scaling')\n",
    "\n",
    "        # Hyperbolic Dual Genmetry Components\n",
    "        self.curvature_log = self.add_weight(shape=(1,), initializer='he_normal',\n",
    "                                             trainable=self.learnable_curvature,\n",
    "                                             name='curvature_log')\n",
    "        self.lorentz_alpha = self.add_weight(shape=(1,), initializer='he_normal', name='lorentz_scale')\n",
    "        self.hyper_beta = self.add_weight(shape=(feature_dim,), initializer='he_normal', name='beta_scale')\n",
    "        \n",
    "        self.hyper_gate = self.add_weight(shape=(1,), initializer='ones', name='hyper_gate')\n",
    "        self.hyper_gate1 = self.add_weight(shape=(1,), initializer='ones', name='hyper_gate1')\n",
    "\n",
    "        # Cross-modality Gates\n",
    "        self.cross_gate = self.add_weight(shape=(feature_dim,), initializer='ones', name='cross_gate')\n",
    "        self.output_gate = self.add_weight(shape=(feature_dim,), initializer='ones', name='output_gate')\n",
    "\n",
    "    def compute_curvature(self): # Compute leranable curvature read Eqs. 4 and 7 \n",
    "        return tf.clip_by_value(tf.exp(self.curvature_log), 0.1, 10.0)\n",
    "\n",
    "    # MLE of LIL block as for Eq. 7\n",
    "    def lorentz_proj(self, x1, x2, c):\n",
    "\n",
    "        space_part1 = x1\n",
    "        space_part2 = x2\n",
    "        norm_sq1 = tf.reduce_sum(x1 ** 2, axis=-1, keepdims=True)  #tf.reduce_sum(tf.square(x1), axis=-1, keepdims=True)\n",
    "        norm_sq2 = tf.reduce_sum(x2 ** 2, axis=-1, keepdims=True) #tf.reduce_sum(tf.square(x2), axis=-1, keepdims=True)\n",
    "        time1 = tf.sqrt(1 + c * norm_sq1) / c\n",
    "        time2 = tf.sqrt(1 + c * norm_sq2) / c\n",
    "        return tf.concat([time2, space_part1], axis=-1), tf.concat([time1, space_part2], axis=-1)\n",
    "        '''\n",
    "        space_part = x\n",
    "        norm_sq = tf.reduce_sum(x ** 2, axis=-1, keepdims=True)\n",
    "        time_part = tf.sqrt(1 + c * norm_sq) / c\n",
    "        return tf.concat([time_part, space_part], axis=-1)\n",
    "\n",
    "        '''\n",
    "\n",
    "    '''def poincare_proj(self, x1, x2, c):\n",
    "        norm1 = tf.norm(x1, axis=-1, keepdims=True) #+ 1e-6\n",
    "        norm2 = tf.norm(x2, axis=-1, keepdims=True) #+ 1e-6\n",
    "        scale1 = tf.tanh(tf.sqrt(c) * norm1) / norm1\n",
    "        scale2 = tf.tanh(tf.sqrt(c) * norm2) / norm2\n",
    "        return x1 * scale1, x2 * scale2\n",
    "        '''\n",
    "    # MPE of PIL block as for Eq. 4\n",
    "    def poincare_proj(self, x1, x2, c):\n",
    "        norm1 = tf.norm(x1, axis=-1, keepdims=True) #+ 1e-6\n",
    "        norm2 = tf.norm(x2, axis=-1, keepdims=True) #+ 1e-6\n",
    "        scale1 = tf.tanh(tf.sqrt(c) * norm1) * (x1 / (norm1 + 1e-6)) #tf.tanh(tf.sqrt(c) * norm1) / norm1\n",
    "        scale2 = tf.tanh(tf.sqrt(c) * norm2) * (x2 / (norm2 + 1e-6))  #tf.tanh(tf.sqrt(c) * norm2) / norm2\n",
    "        return x1 * scale1, x2 * scale2\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input1, input2 = inputs\n",
    "\n",
    "        \n",
    "        input_shape = tf.shape(input1)\n",
    "        \n",
    "        #flattened_inputs1 = tf.reshape(input1, [-1, input_shape[-1]])  # Flatten along the last axis\n",
    "\n",
    "        # Feature flattening\n",
    "        x1_flat = tf.reduce_mean(input1, axis=[1, 2]) if len(input1.shape) == 4 else input1\n",
    "        x2_flat = tf.reduce_mean(input2, axis=[1, 2]) if len(input2.shape) == 4 else input2\n",
    "\n",
    "        ## Use DCT for capturing frequency information\n",
    "        x1_flat = tf.signal.dct(x1_flat, type=2, norm='ortho')\n",
    "        x2_flat = tf.signal.dct(x2_flat, type=2, norm='ortho')\n",
    "\n",
    "        \n",
    "\n",
    "        #. Multimodal Hyperbolic Dual-Geometry Attention (MHDGA)\n",
    "        c = self.compute_curvature()\n",
    "        adjusted_S = self.S * tf.sigmoid(c)\n",
    "        adjusted_c = c * tf.reduce_mean(tf.sigmoid(self.S))\n",
    "\n",
    "        \n",
    "        # MQIA for estimating quantum states for each modality input\n",
    "        psi1 = tf.complex(tf.matmul(x1_flat, self.psi_real), tf.matmul(x1_flat, self.psi_imag))\n",
    "        psi2 = tf.complex(tf.matmul(x2_flat, self.psi_real), tf.matmul(x2_flat, self.psi_imag))\n",
    "\n",
    "        \n",
    "        # Mutual Guidance for MQIA through MLE of LIL block for each modality input as self.lorentz_proj() used in LIL block as for Eq. 9\n",
    "        h_psi1, h_psi2 = self.lorentz_proj(tf.math.real(psi1), tf.math.real(psi2), adjusted_c)\n",
    "        prob1 = tf.math.real(psi1 * tf.math.conj(psi1)) #+ 1e-8\n",
    "        prob2 = tf.math.real(psi2 * tf.math.conj(psi2)) #+ 1e-8\n",
    "        lorentz_factor1 = tf.norm(h_psi1[..., 1:], axis=-1, keepdims=True)\n",
    "        lorentz_factor2 = tf.norm(h_psi2[..., 1:], axis=-1, keepdims=True)\n",
    "\n",
    "        ## Attention maps learned from MQIA for each modality input as for Eq. 9\n",
    "        \n",
    "        scaled_prob1 = prob1 * tf.pow(lorentz_factor1, adjusted_S - 2)  \n",
    "        scaled_prob2 = prob2 * tf.pow(lorentz_factor2, adjusted_S - 2)\n",
    "        \n",
    "        fractal_att1 = tf.nn.softmax(scaled_prob1, axis=-1)\n",
    "        fractal_att2 = tf.nn.softmax(scaled_prob2, axis=-1)\n",
    "\n",
    "        \n",
    "        # Multimodal Hyperbolic Dual-Geometry Attention (MHDGA)\n",
    "        h_lorentz1, h_lorentz2 = self.lorentz_proj(x1_flat, x2_flat, adjusted_c) # for LIL block for hyperbloc space computation as for Eq. 7\n",
    "        h_poincare1, h_poincare2 = self.poincare_proj(x1_flat, x2_flat, adjusted_c) # for PIL block for hyperbloc space computation as for Eq. 5\n",
    "\n",
    "        ## Ref. Eq. 6 to estimate times and frequency components for LIL:\n",
    "        t1, x1 = h_lorentz1[..., :1], h_lorentz1[..., 1:]\n",
    "        t2, x2 = h_lorentz2[..., :1], h_lorentz2[..., 1:]\n",
    "\n",
    "\n",
    "        ## Bais estimation from MQIA for LIL block to generate attention maps see Eq. 8:\n",
    "        quantum_bias1 = tf.matmul(fractal_att1, tf.transpose(self.psi_real))\n",
    "        quantum_bias2 = tf.matmul(fractal_att2, tf.transpose(self.psi_real))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # Lorentz attention weights is computed via Minkowski inner product (see Eq. 8):\n",
    "\n",
    "        lorentz_att1 = self.lorentz_alpha * (-t1**2 + tf.reduce_sum((x1 + quantum_bias1)**2 * self.hyper_beta, axis=-1, keepdims=True))\n",
    "        lorentz_att2 = self.lorentz_alpha * (-t2**2 + tf.reduce_sum((x2 + quantum_bias2)**2 * self.hyper_beta, axis=-1, keepdims=True))\n",
    "\n",
    "        # Poincare attention weights is computed (see Eq. 5):\n",
    "        poincare_att1 = tf.reduce_sum(h_poincare1 * x1_flat, axis=-1, keepdims=True)\n",
    "        poincare_att2 = tf.reduce_sum(h_poincare2 * x2_flat, axis=-1, keepdims=True)\n",
    "\n",
    "        #gate_factor = tf.tanh(self.hyper_gate)\n",
    "        gate_factor = self.hyper_gate\n",
    "        gate_factor1 = self.hyper_gate1\n",
    "\n",
    "        # dual-geometry attention maps (see Eq. 3):\n",
    "        hyper_att1 = tf.nn.sigmoid(gate_factor * lorentz_att1 + gate_factor1 * poincare_att1)\n",
    "        hyper_att2 = tf.nn.sigmoid(gate_factor * lorentz_att2 + gate_factor1 * poincare_att2)\n",
    "\n",
    "        # Reshape attention maps\n",
    "        def expand(x, target_shape):\n",
    "            if len(target_shape) == 4:\n",
    "                x = tf.expand_dims(tf.expand_dims(x, 1), 1)\n",
    "                return tf.tile(x, [1, target_shape[1], target_shape[2], 1])\n",
    "            return x\n",
    "\n",
    "        fractal_att1 = expand(fractal_att1, input1.shape)\n",
    "        fractal_att2 = expand(fractal_att2, input1.shape)\n",
    "        \n",
    "        hyper_att1 = expand(hyper_att1, input1.shape)\n",
    "        hyper_att2 = expand(hyper_att2, input2.shape)\n",
    "        \n",
    "        \n",
    "        cross_gate = tf.reshape(self.cross_gate, (1, 1, 1, -1))\n",
    "        output_gate1 = tf.reshape(self.output_gate, (1, 1, 1, -1))\n",
    "        output_gate2 = tf.reshape(self.output_gate, (1, 1, 1, -1))\n",
    "        output_gate3 = tf.reshape(self.output_gate, (1, 1, 1, -1))\n",
    "        output_gate4 = tf.reshape(self.output_gate, (1, 1, 1, -1))\n",
    "\n",
    "        #hyper_att = hyper_att1 + hyper_att2\n",
    "        \n",
    "        # Cross Fusion (see Eqs. 1, 2, 10):\n",
    "        fractal_out1 = input2 * cross_gate * fractal_att1 #* attention1 #* hyper_att1\n",
    "        hyper_out1 = input2 * cross_gate * hyper_att1 #* attention1\n",
    "        \n",
    "        fractal_out2 = input1 * cross_gate * fractal_att2 #* attention2 #* hyper_att1\n",
    "        hyper_out2 = input1 * cross_gate * hyper_att2 #* attention2\n",
    "        \n",
    "        #  Multimodal Attention Fusion Gating Block:\n",
    "        return ((output_gate1 * fractal_out2) + (output_gate2 * hyper_out2)), ((output_gate3 * fractal_out1) + (output_gate4 * hyper_out1)) #+ (output_gate4 * attn1) + (output_gate4 * attn2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## EXtending MHCF for devsiing SIR module\n",
    "def multi_kernel_groupwise_conv1(x, filters, groups=8, strides=2):\n",
    "    \n",
    "\n",
    "    # Multi-Kernel Parallel Convolutions with Different Receptive Fields\n",
    "    conv1x1 = layers.Conv2D(filters // 4, kernel_size=1, groups=groups, padding=\"same\")(x)\n",
    "    conv3x3 = layers.DepthwiseConv2D(kernel_size=3, padding=\"same\")(x)\n",
    "    conv5x5 = layers.DepthwiseConv2D(kernel_size=5, padding=\"same\")(x)\n",
    "    conv_dilated = layers.DepthwiseConv2D(kernel_size=3, dilation_rate=2, padding=\"same\")(x)\n",
    "\n",
    "    # Feature Fusion via Concatenation\n",
    "    x1 = layers.Concatenate()([conv1x1, conv3x3, conv5x5, conv_dilated])\n",
    "\n",
    "    # Channel Shuffle for Better Feature Mixing\n",
    "    def channel_shuffle(x, groups):\n",
    "        batch, height, width, channels = tf.unstack(tf.shape(x))\n",
    "        x = tf.reshape(x, [-1, height, width, groups, channels // groups])\n",
    "        x = tf.transpose(x, [0, 1, 2, 4, 3])\n",
    "        x = tf.reshape(x, [-1, height, width, channels])\n",
    "        return x\n",
    "\n",
    "    x1 = layers.Lambda(lambda x: channel_shuffle(x, groups))(x1)\n",
    "\n",
    "    # Depthwise + Grouped Convolutions Hybrid\n",
    "    x1 = layers.DepthwiseConv2D(kernel_size=3, padding=\"same\")(x1)\n",
    "    x1 = layers.Conv2D(filters, kernel_size=1, groups=groups, padding=\"same\")(x1)\n",
    "\n",
    "    # Downsampling x1\n",
    "    x1 = layers.DepthwiseConv2D(kernel_size=3, strides=strides, padding=\"same\")(x1)\n",
    "\n",
    "    # **Fix: Ensure x has the same number of channels as x1**\n",
    "    x = layers.Conv2D(filters, kernel_size=1, groups=groups, padding=\"same\")(x)\n",
    "    x = layers.DepthwiseConv2D(kernel_size=3, strides=strides, padding=\"same\")(x)\n",
    "\n",
    "    # Residual Connection\n",
    "    x = layers.Add()([x, x1])\n",
    "    x = layers.Activation('gelu')(x)  # GELU activation for better convergence\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# MHCF for EMRC block\n",
    "def multi_kernel_groupwise_conv3(x, filters, groups=8, strides=2, use_se=True):\n",
    "    # GPC\n",
    "    conv1x1 = layers.Conv2D(filters, kernel_size=1, groups=groups, strides=strides, padding=\"same\", use_bias=False)(x)\n",
    "    conv1x1 = layers.BatchNormalization()(conv1x1)\n",
    "\n",
    "    # DDC\n",
    "    conv3x3 = layers.DepthwiseConv2D(kernel_size=3, dilation_rate=1,strides=strides,  padding=\"same\", use_bias=False)(x)\n",
    "    \n",
    "    #conv3x3 = layers.GaussianBlur(kernel_size=3, sigma=1.0)(conv3x3)\n",
    "    #if strides==2:\n",
    "     #   conv3x3 = layers.AveragePooling2D(2, 2, padding=\"same\")(conv3x3)\n",
    "\n",
    "    conv3x3 = layers.BatchNormalization()(conv3x3)\n",
    "\n",
    "    # DWC\n",
    "    conv5x5 = layers.DepthwiseConv2D(kernel_size=5, strides=strides, padding=\"same\", use_bias=False)(x)\n",
    "    conv5x5 = layers.BatchNormalization()(conv5x5)\n",
    "\n",
    "    # Concatenation and 1x1 Fusion\n",
    "    x1 = layers.Concatenate()([conv1x1, conv3x3, conv5x5])\n",
    "\n",
    "    def channel_shuffle(x, groups):\n",
    "        batch, height, width, channels = tf.unstack(tf.shape(x))\n",
    "        x = tf.reshape(x, [-1, height, width, groups, channels // groups])\n",
    "        x = tf.transpose(x, [0, 1, 2, 4, 3])\n",
    "        x = tf.reshape(x, [-1, height, width, channels])\n",
    "        return x\n",
    "\n",
    "    x1 = layers.Lambda(lambda x: channel_shuffle(x, groups))(x1)\n",
    "\n",
    "    \n",
    "    x1 = layers.Conv2D(filters, kernel_size=1, groups=groups, padding=\"same\", use_bias=False)(x1)\n",
    "    \n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "\n",
    "    # Residual Connection\n",
    "    x = layers.Conv2D(filters=filters, kernel_size=1, strides=strides, groups= 8, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Add()([x, x1])\n",
    "    x = layers.Activation('gelu')(x)  # GELU activation for better convergence\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "# Single branch of EMRC for each modality input, such as x_i\n",
    "\n",
    "def RGSA(x, filters, strides=(1, 1), use_projection=False):\n",
    "    shortcut = x  # Save the original input for residual connection\n",
    "\n",
    "    # First MHCF\n",
    "    x = multi_kernel_groupwise_conv3(x, filters=filters, groups=8, strides=strides)\n",
    "\n",
    "    # Normalization and Activation\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    # Second MHCF\n",
    "    x = multi_kernel_groupwise_conv3(x, filters=filters, groups=8, strides=(1, 1))  # Strides=1 to avoid mismatch\n",
    "    x = layers.Conv2D(filters, kernel_size=(1, 1), padding=\"same\")(x)  # Pointwise conv for channel mixing\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Adjust Shortcut if Needed (Ensure Matching Shape)\n",
    "    if strides != (1, 1) or use_projection:\n",
    "        shortcut = layers.Conv2D(filters, kernel_size=(1, 1), strides=strides, groups=8, padding=\"same\")(shortcut)  # Downsampling shortcut\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    #x, shortcut = MACFusion(units=filters)([x, shortcut])\n",
    "    # Residual Connection (Ensure Same Shape)\n",
    "    x = layers.Add()([x, shortcut])\n",
    "\n",
    "    # Final Activation\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def EMRC(x1, x2, filters, strides):\n",
    "    \"\"\"\n",
    "    Efficient Multiscale Residual Convolution (EMRC) block.\n",
    "\n",
    "    Applies the RGSA module to each of the two input feature maps,\n",
    "    using a projection shortcut when the spatial resolution or channel\n",
    "    count changes.\n",
    "\n",
    "    Args:\n",
    "        x1: First input tensor.\n",
    "        x2: Second input tensor.\n",
    "        filters: Number of output channels for RGSA.\n",
    "        strides: Stride to use in RGSA.\n",
    "\n",
    "    Returns:\n",
    "        A tuple (x1, x2) of output tensors after RGSA.\n",
    "    \"\"\"\n",
    "    # (optional) fast input check\n",
    "    if not (isinstance(filters, int) and filters > 0):\n",
    "        raise ValueError(f\"`filters` must be a positive int, got {filters}\")\n",
    "    if not (isinstance(strides, int) and strides > 0):\n",
    "        raise ValueError(f\"`strides` must be a positive int, got {strides}\")\n",
    "\n",
    "    x1 = RGSA(x1, filters=filters, strides=strides, use_projection=True)\n",
    "    x2 = RGSA(x2, filters=filters, strides=strides, use_projection=True)\n",
    "    return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def info_fusion(x_1, x_2, filter):\n",
    "    x11 = multi_kernel_groupwise_conv1(x_1, filters=filter, groups=8, strides=(2,2))\n",
    "    x21 = multi_kernel_groupwise_conv1(x_2, filters=filter, groups=8, strides=(2,2))\n",
    "\n",
    "    return x11, x21\n",
    "\n",
    "def info_fusion1(x_1, x_2, filter):\n",
    "    x11 = multi_kernel_groupwise_conv1(x_1, filters=filter, groups=8, strides=(1,1))\n",
    "    x21 = multi_kernel_groupwise_conv1(x_2, filters=filter, groups=8, strides=(1,1))\n",
    "\n",
    "    return x11, x21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def SIR(x1, x2, f):\n",
    "    if f == 64:\n",
    "        x111, x211 = info_fusion(x1, x2, 2 * f)\n",
    "        x111, x211 = info_fusion(x111, x211, 4 * f)\n",
    "        x111, x211 = info_fusion(x111, x211, 8 * f)\n",
    "        return x111, x211\n",
    "\n",
    "    elif f == 128:\n",
    "        x111, x211 = info_fusion(x1, x2, 2 * f)\n",
    "        x111, x211 = info_fusion(x111, x211, 4 * f)\n",
    "        return x111, x211\n",
    "\n",
    "    elif f == 256:\n",
    "        x111, x211 = info_fusion(x1, x2, 2 * f)\n",
    "        return x111, x211\n",
    "\n",
    "    elif f == 512:\n",
    "        x111, x211 = info_fusion1(x1, x2, f)\n",
    "        return x111, x211\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported fusion factor: {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## HySAM\n",
    "def PCMFA(x1, x2, f):\n",
    "    \n",
    "    x1, x2 = MACFusion(units=f)([x1, x2]) # First PCMFA\n",
    "    x1, x2 = MACFusion(units=f)([x1, x2]) # Second PCMFA\n",
    "\n",
    "    return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## HyFuse\n",
    "\n",
    "def EHF1(x1, x2, f, s):\n",
    "    x1, x2 = EMRC(x1, x2, f, s) # Call EMRC module\n",
    "    x1, x2 = PCMFA(x1, x2, f) # # Call PCMFA module\n",
    "    return x1, x2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.initializers import Ones, Constant\n",
    "\n",
    "## LLF \n",
    "\n",
    "class LF(layers.Layer):\n",
    "    def build(self, input_shape):\n",
    "        # input_shape: list of two shapes, each (B, H, W, C)\n",
    "        # we use a single scalar per tensor (broadcastable to all channels)\n",
    "        \n",
    "\n",
    "        self.global_scale1 = self.add_weight(\n",
    "            name=\"global_scale1\",\n",
    "            shape=(1,1,1,1),\n",
    "            initializer=Ones(),      # starts at 1.0\n",
    "            trainable=True\n",
    "        )\n",
    "        # or, if you want a tiny deviation around 1:\n",
    "        self.global_scale2 = self.add_weight(\n",
    "            name=\"global_scale2\",\n",
    "            shape=(1,1,1,1),\n",
    "            initializer=Constant(value=1.0),  \n",
    "            # this gives values ~ N(1,0.01)\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x1, x2 = inputs\n",
    "        # scale each branch by its learnable scalar\n",
    "        x1_scaled = x1 * self.global_scale1\n",
    "        x2_scaled = x2 * self.global_scale2\n",
    "        # concatenate along channel axis\n",
    "        return layers.Concatenate(axis=-1)([x1_scaled, x2_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## HyFuse\n",
    "\n",
    "def EHF2(x1, x2, f, s):\n",
    "    x1, x2 = EMRC(x1, x2, f, s) # Call EMRC module\n",
    "    \n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    x2 = layers.BatchNormalization()(x2)\n",
    "    \n",
    "    x1, x2 = PCMFA(x1, x2, f) # Call PCMFA module\n",
    "    \n",
    "    x111, x211 = SIR(x1, x2, f) ## Call SIR module\n",
    "\n",
    "    #x1 = layers.Concatenate(axis = -1)([x1, x2])\n",
    "    \n",
    "    x1 = LF()([x1, x2])  # Use Learnable Late Fusion (LF) for capturing multimodal information\n",
    "    \n",
    "    x1 = layers.Conv2D(f, kernel_size=(1, 1), groups=8, \n",
    "                       padding=\"same\")(x1) \n",
    "    \n",
    "    return x1, x111, x211    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## HyFuse\n",
    "\n",
    "def EHF(x1, x2, filters, strides1, strides2):\n",
    "    \"\"\"\n",
    "    Efficient Hybrid Fusion (EHF) block.\n",
    "\n",
    "    - If filters == 64, applies two rounds of EHF1 at strides2 and returns (x1, x2).\n",
    "    - If filters >= 128, applies EHF1 at strides1 then EHF2 at strides2 and returns (x1, x2, x11, x22).\n",
    "    \"\"\"\n",
    "    if filters == 64:\n",
    "        x1, x2 = EHF1(x1, x2, filters, strides2)\n",
    "        x1, x2 = EHF1(x1, x2, filters, strides2)\n",
    "        return x1, x2\n",
    "\n",
    "    elif filters == 128:\n",
    "        x1, x2 = EHF1(x1, x2, filters, strides1)\n",
    "        x1, x111, x211 = EHF2(x1, x2, filters, strides2)\n",
    "        return x1, x111, x211\n",
    "\n",
    "    elif filters == 256:\n",
    "        x1, x2 = EHF1(x1, x2, filters, strides1)\n",
    "        x1, x111, x211 = EHF2(x1, x2, filters, strides2)\n",
    "        return x1, x111, x211\n",
    "\n",
    "    elif filters == 512:\n",
    "        x1, x2 = EHF1(x1, x2, filters, strides1)\n",
    "        x1, x111, x211 = EHF2(x1, x2, filters, strides2)\n",
    "        return x1, x111, x211\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported filter size: {filters}. Expected 64 or >=128.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## MSIL\n",
    "\n",
    "def residual_GLC_branch1(inputs1, inputs2, inputs3, inputs4):\n",
    "\n",
    "    # Modality input 1\n",
    "    x1 = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding='same')(inputs1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = tf.keras.layers.Activation('relu')(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x1)\n",
    "\n",
    "    # Modality input 2\n",
    "    x2 = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding='same')(inputs2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x2)\n",
    "\n",
    "    \n",
    "    x1, x2 = EHF(x1, x2, filters=64, strides1=1, strides2=1)\n",
    "\n",
    "    x1, x111, x211 = EHF(x1, x2, filters = 128, strides1=1, strides2=2)\n",
    "\n",
    "\n",
    "    # Modality input 3\n",
    "    x3 = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding='same')(inputs3)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x3)\n",
    "\n",
    "    x2 = multi_kernel_groupwise_conv3(x3, filters=256, groups=8, strides=2)\n",
    "    \n",
    "    x1, x1111, x2111 = EHF(x1, x2, filters = 256, strides1=1, strides2=2)\n",
    "\n",
    "    \n",
    "    # Modality input 4\n",
    "    x4 = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding='same')(inputs4)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = tf.keras.layers.Activation('relu')(x4)\n",
    "    x4 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x4)\n",
    "    \n",
    "    \n",
    "    x2 = multi_kernel_groupwise_conv3(x4, filters=512, groups=8, strides=2)\n",
    "    x2 = multi_kernel_groupwise_conv3(x2, filters=512, groups=8, strides=2)\n",
    "    \n",
    "    #x2 = RGSA(x2, filters=512, strides=(2, 2), use_projection=True)\n",
    "\n",
    "    x1, x11111, x21111 = EHF(x1, x2, filters = 512, strides1=1, strides2=2)\n",
    "    \n",
    "    \n",
    "    return x1, x111, x211, x1111, x2111, x11111, x21111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''class CIndexCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Predict risk scores on the full validation set\n",
    "        pred = self.model.predict(X_val_multi, verbose=0).reshape(-1)\n",
    "        #risk_scores = preds[2].reshape(-1)\n",
    "        durs = y_val_tab[:, 0]\n",
    "        evts = y_val_tab[:, 1].astype(bool)\n",
    "        ci = concordance_index(durs, -pred, evts)\n",
    "        logs = logs or {}\n",
    "        logs['val_c_index'] = ci\n",
    "        print(f\" — val_c_index: {ci:.4f}\")\n",
    "'''\n",
    "\n",
    "class CIndexCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, val_inputs, val_cox_y):\n",
    "        \"\"\"\n",
    "        val_inputs: list of your four validation inputs,\n",
    "                    e.g. [X_val_s, X_val_h1, X_val_multi, X_val_m1]\n",
    "        val_cox_y:  the (n,2) array of [durations, events] for the Cox head\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.val_inputs = val_inputs\n",
    "        self.val_cox_y   = val_cox_y\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        # 1) predict returns a list of outputs, one per head\n",
    "        preds = self.model.predict(self.val_inputs, batch_size = 4, verbose=0)\n",
    "        # 2) pick out the Cox‐head predictions (assuming it's the 3rd head: index 2)\n",
    "        risk_scores = preds[2].reshape(-1)\n",
    "\n",
    "        # 3) pull durations/events\n",
    "        durations = self.val_cox_y[:, 0]\n",
    "        events    = self.val_cox_y[:, 1].astype(bool)\n",
    "\n",
    "        # 4) compute C‐index\n",
    "        ci = concordance_index(durations, -risk_scores, events)\n",
    "        logs['val_c_index'] = ci\n",
    "\n",
    "        print(f\" — val_c_index: {ci:.4f}\")\n",
    "\n",
    "\n",
    "#cidx_cb = CIndexCallback()\n",
    "\n",
    "val_inputs = [X_val_s, X_val_h1, X_val_multi, X_val_m1]\n",
    "# the Cox‐head targets for val:\n",
    "val_cox_y = y_val_multi  # shape (n_val, 2)\n",
    "\n",
    "cidx_cb = CIndexCallback(val_inputs, val_cox_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def neg_log_partial_likelihood(y_true, y_pred):\n",
    "    eps = 1e-8\n",
    "\n",
    "    # unpack\n",
    "    durations = y_true[:, 0]\n",
    "    events    = y_true[:, 1]\n",
    "\n",
    "    # sort by descending time\n",
    "    order = tf.argsort(durations, direction=\"DESCENDING\")\n",
    "    p = tf.gather(tf.reshape(y_pred, [-1]), order)\n",
    "\n",
    "    # clip the raw predictions to a safe window before exp\n",
    "    p = tf.clip_by_value(p, -10.0, 10.0)\n",
    "\n",
    "    # hazard ratio\n",
    "    hr = tf.exp(p)\n",
    "    hr = tf.clip_by_value(hr, eps, 1e6)\n",
    "\n",
    "    # cumulative hazard\n",
    "    cum_h = tf.cumsum(hr) + eps\n",
    "    log_cum = tf.math.log(cum_h)\n",
    "\n",
    "    diff = p - log_cum\n",
    "    loss = -tf.reduce_sum(diff * tf.gather(events, order))\n",
    "\n",
    "    return loss / (tf.reduce_sum(events) + eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class ConcordanceIndex(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='c_index', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.y_true_vals = []\n",
    "        self.y_pred_vals = []\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.y_true_vals.append(tf.reshape(y_true, [-1]))\n",
    "        self.y_pred_vals.append(tf.reshape(y_pred, [-1]))\n",
    "\n",
    "    def result(self):\n",
    "        y_true = tf.concat(self.y_true_vals, axis=0)\n",
    "        y_pred = tf.concat(self.y_pred_vals, axis=0)\n",
    "        return self._concordance_index(y_true, y_pred)\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.y_true_vals = []\n",
    "        self.y_pred_vals = []\n",
    "\n",
    "    def _concordance_index(self, y_true, y_pred):\n",
    "        n = tf.shape(y_true)[0]\n",
    "        i = tf.range(n)\n",
    "        j = tf.range(n)\n",
    "        ii, jj = tf.meshgrid(i, j)\n",
    "        mask = tf.math.greater(y_true[ii], y_true[jj])\n",
    "        pred_diff = y_pred[ii] - y_pred[jj]\n",
    "        concordant = tf.math.greater(pred_diff, 0)\n",
    "        ties = tf.math.equal(pred_diff, 0)\n",
    "        concordant = tf.cast(concordant, tf.float32)\n",
    "        ties = tf.cast(ties, tf.float32)\n",
    "        concordant = tf.where(mask, concordant, tf.zeros_like(concordant))\n",
    "        ties = tf.where(mask, ties, tf.zeros_like(ties))\n",
    "        total = tf.reduce_sum(tf.cast(mask, tf.float32))\n",
    "        return (tf.reduce_sum(concordant) + 0.5 * tf.reduce_sum(ties)) / (total + tf.keras.backend.epsilon())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#def build_resnet18(input_shape=(128, 128, 3), num_classes=2):\n",
    "def build_model():\n",
    "\n",
    "    input_shape=(128, 128, 3)\n",
    "    inputs1 = Input(shape=input_shape) # Modality input 1\n",
    "    inputs2 = Input(shape=input_shape) # Modality input 2\n",
    "    inputs3 = Input(shape=input_shape) # Modality input 3\n",
    "    inputs4 = Input(shape=input_shape) # Modality input 4\n",
    "    \n",
    "    import tensorflow.keras.layers as L\n",
    "    \n",
    "    #input_data = Input(shape=input_shape, name='input_data')\n",
    "    # Initial convolutional layer\n",
    "    \n",
    "    #x1, x2 = residual_GLC_branch1(inputs1, inputs2)\n",
    "    \n",
    "    ## Call MSIL\n",
    "\n",
    "    x1, x111, x211, x1111, x2111, x11111, x21111 = residual_GLC_branch1(inputs1, inputs2, inputs3, inputs4)\n",
    "    #print('x:',x.shape)\n",
    "    \n",
    "    \n",
    "\n",
    "    con1 = tf.keras.layers.Concatenate(axis=-1)([x111, x1111, x11111])\n",
    "    con2 = tf.keras.layers.Concatenate(axis=-1)([x211, x2111, x21111])\n",
    "\n",
    "    con = tf.keras.layers.Concatenate(axis=-1)([x1, con1, con2])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #con = tf.keras.layers.Concatenate(axis=-1)([x1, x111, x1111, x11111, x211, x2111, x21111])\n",
    "    \n",
    "    con = tf.keras.layers.Dropout(0.25)(con, training = True)  ## MCD ####\n",
    "    \n",
    "    ## HMML\n",
    "    x = GlobalAveragePooling2D()(con)\n",
    "    \n",
    "    \n",
    "    outputs1 = Dense(5, activation='softmax')(x) # Output layer for modality input 1\n",
    "    outputs2 = Dense(7, activation='softmax')(x) # Output layer for modality input 2\n",
    "    outputs3 = Dense(1, activation=\"linear\")(x) # Output layer for modality input 3\n",
    "    outputs4 = Dense(2, activation='sigmoid')(x) # Output layer for modality input 4\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model([inputs1, inputs2, inputs3, inputs4], [outputs1, outputs2, outputs3, outputs4])\n",
    "    #return model\n",
    "    #print(model.summary())\n",
    "\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "    initial_gamma1 = 0.25\n",
    "    initial_gamma2 = 0.25\n",
    "    initial_gamma3 = 0.25\n",
    "    \n",
    "    \n",
    "    \n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "    #opt = Adam(learning_rate=1e-4, clipnorm=1.0)\n",
    "    \n",
    "    #opt = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.9, epsilon=None, amsgrad=False)\n",
    "    \n",
    "    # Compile the model with the custom optimizer\n",
    "    model.compile(optimizer='adam', loss=['categorical_crossentropy', 'categorical_crossentropy', neg_log_partial_likelihood, \n",
    "                                          'binary_crossentropy'],\n",
    "                  loss_weights=[initial_gamma1, initial_gamma2, initial_gamma3, (1 -  (initial_gamma1 + initial_gamma2 + initial_gamma3))],\n",
    "                  metrics={\n",
    "        'h':    ['accuracy', tf.keras.metrics.AUC(name='auc')],\n",
    "        's':    ['accuracy', tf.keras.metrics.AUC(name='auc')],\n",
    "        'multi':[ConcordanceIndex(name='c_index')],\n",
    "        'm1':   ['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    }\n",
    "                 )\n",
    "       \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "def checkpoint_callback():\n",
    "\n",
    "    checkpoint_filepath = 'best1_model.keras'\n",
    "\n",
    "    model_checkpoint_callback= ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                           save_weights_only=False,\n",
    "                           #frequency='epoch',\n",
    "                           monitor='val_loss',\n",
    "                           save_best_only=True,\n",
    "                            mode='min',\n",
    "                           verbose=1)\n",
    "\n",
    "    return model_checkpoint_callback\n",
    "\n",
    "def early_stopping(patience):\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=60, verbose=1)\n",
    "    return es_callback\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=50, verbose = 1, min_lr=0.000001)\n",
    "\n",
    "checkpoint_callback = checkpoint_callback()\n",
    "\n",
    "early_stopping = early_stopping(patience=100)\n",
    "callbacks = [#cidx_cb, \n",
    "             checkpoint_callback, early_stopping, reduce_lr]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Fit the model with callbacks\n",
    "history = model.fit([X_train_s, X_train_h, X_train_multi, X_train_m1], [y_train_s, y_train_h, y_train_multi, y_train_m1],\n",
    "                    epochs=200,\n",
    "                    validation_data=([X_val_s, X_val_h1, X_val_multi, X_val_m1], [y_val_s, y_val_h1, y_val_multi, y_val_m1]), verbose=1, \n",
    "                    shuffle=True, #batch_size=40,\n",
    "                    callbacks=callbacks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "# 1) Generate or define your five seeds\n",
    "import random\n",
    "\n",
    "# 1) Generate five random 32-bit integer seeds\n",
    "#    (you can set a seed here if you want reproducible seed-generation)\n",
    "seeds = np.random.randint(0, 2**31 - 1, size=5).tolist()\n",
    "print(\"Using seeds:\", seeds)\n",
    "\n",
    "\n",
    "# 2) Prepare empty lists for each modality\n",
    "modalities = ['Dermoscopy', 'Cytology', 'ECG', 'EHR']\n",
    "stats = {\n",
    "    mod: {\n",
    "        'accs': [],\n",
    "        'metrics': []  # 'auc' or 'c_index' depending on modality\n",
    "    } for mod in modalities\n",
    "}\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    # ── reproducibility ───────────────────────────────────────────\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # ── build & compile ───────────────────────────────────────────\n",
    "    model = build_model()  # your model builder\n",
    "    \n",
    "\n",
    "    # ── fit ───────────────────────────────────────────────────────\n",
    "    model.fit(\n",
    "        [X_train_h, X_train_s, X_train_multi, X_train_m1],\n",
    "        [y_train_h, y_train_s, y_train_multi, y_train_m1],\n",
    "        epochs=200,\n",
    "        validation_data=(\n",
    "            [X_val_h1, X_val_s, X_val_multi, X_val_m1],\n",
    "            [y_val_h1, y_val_s, y_val_multi, y_val_m1]\n",
    "        ),\n",
    "        verbose=0,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # ── evaluate ─────────────────────────────────────────────────\n",
    "    names, results = model.metrics_names, model.evaluate(\n",
    "        [X_test_h1, X_test_s, X_test_multi, X_test_m1],\n",
    "        [y_test_h1, y_test_s, y_test_multi, y_test_m1],\n",
    "        verbose=0\n",
    "    )\n",
    "    res = dict(zip(names, results))\n",
    "\n",
    "    # ── collect per‐modality ──────────────────────────────────────\n",
    "    # After model evaluation\n",
    "    for mod in modalities:\n",
    "        stats[mod]['accs'].append(res[f\"{mod}_accuracy\"])\n",
    "        if mod == 'ECG':  # Assuming 'multi' corresponds to 'ECG'\n",
    "            stats[mod]['metrics'].append(res[f\"{mod}_c_index\"])\n",
    "        else:\n",
    "            stats[mod]['metrics'].append(res[f\"{mod}_auc\"])\n",
    "\n",
    "\n",
    "for mod in modalities:\n",
    "    accs = np.array(stats[mod]['accs'])\n",
    "    metrics = np.array(stats[mod]['metrics'])\n",
    "    metric_name = 'C-Index' if mod == 'ECG' else 'AUC'\n",
    "    print(f\"Modality {mod.upper()}:\")\n",
    "    print(f\"  ACC: {accs.mean():.4f} ± {accs.std():.4f}\")\n",
    "    print(f\"  {metric_name}: {metrics.mean():.4f} ± {metrics.std():.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4680816,
     "sourceId": 7957692,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6597049,
     "sourceId": 10653461,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7176743,
     "sourceId": 11454031,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7503501,
     "sourceId": 11934914,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7503955,
     "sourceId": 11935647,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
